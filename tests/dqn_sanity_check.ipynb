{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from models.dqn import DQN\n",
    "from rl_models.replay_buffer import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evgeny/anaconda3/lib/python3.11/site-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\", render_mode=\"rgb_array\").env\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "n_actions, state_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQN(state_dim, n_actions, lr=1e-4)\n",
    "buffer = ReplayBuffer(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(env, t_max=1000, epsilon=0.0, train=False):\n",
    "    total_reward = 0\n",
    "    s, _ = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        s = torch.tensor(s, dtype=torch.float)\n",
    "        \n",
    "        if train and np.random.rand() < epsilon:\n",
    "            a = torch.tensor(env.action_space.sample())\n",
    "        else:\n",
    "            a = agent.choose_action(s)\n",
    "        \n",
    "        next_s, r, done, _, _ = env.step(a.numpy())\n",
    "        \n",
    "        next_s = torch.tensor(next_s, dtype=torch.float)\n",
    "        r = torch.tensor(r, dtype=torch.float)\n",
    "        batch = [[[s], [a], [r], [next_s], [done]]]\n",
    "        if train:\n",
    "            agent.learning_step(batch)\n",
    "            agent.update_network_parameters()\n",
    "\n",
    "        total_reward += r\n",
    "        s = next_s\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76876/681407464.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  s = torch.tensor(s, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0\tmean reward = 13.890\t\n",
      "epoch #1\tmean reward = 14.580\t\n",
      "epoch #2\tmean reward = 14.810\t\n",
      "epoch #3\tmean reward = 24.400\t\n",
      "epoch #4\tmean reward = 30.130\t\n",
      "epoch #5\tmean reward = 37.730\t\n",
      "epoch #6\tmean reward = 57.080\t\n",
      "epoch #7\tmean reward = 62.310\t\n",
      "epoch #8\tmean reward = 101.540\t\n",
      "epoch #9\tmean reward = 117.190\t\n",
      "epoch #10\tmean reward = 143.930\t\n",
      "epoch #11\tmean reward = 139.410\t\n",
      "epoch #12\tmean reward = 152.040\t\n",
      "epoch #13\tmean reward = 159.850\t\n",
      "epoch #14\tmean reward = 171.330\t\n",
      "epoch #15\tmean reward = 196.840\t\n",
      "epoch #16\tmean reward = 212.540\t\n",
      "epoch #17\tmean reward = 222.070\t\n",
      "epoch #18\tmean reward = 248.810\t\n",
      "epoch #19\tmean reward = 319.800\t\n",
      "You Win!\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.5\n",
    "\n",
    "for i in range(1000):\n",
    "    session_rewards = [generate_session(env, t_max=1000, epsilon=epsilon, train=True) for _ in range(100)]\n",
    "    print(\"epoch #{}\\tmean reward = {:.3f}\\t\".format(i, np.mean(session_rewards)))\n",
    "\n",
    "    epsilon *= 0.99\n",
    "    if np.mean(session_rewards) > 300:\n",
    "        print(\"You Win!\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
